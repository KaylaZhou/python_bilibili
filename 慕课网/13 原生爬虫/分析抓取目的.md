# 第十三章 实战: 原生爬虫

## 爬虫的前奏

- 明确目的,需求
- 找到数据对应的网页
- 分析网页的结构找到数据所在的标签位置

### 如何爬取数据

- 首先要了解要爬取网站的结果
- 模拟 http 请求,向服务器发送这个请求,获取到服务器返回给我们的 html
- 用正则表达式提取我们要的数据(如:名字,人气)

### 代码调试的方法

- 断点调试
- print
- 单元测试

### 原则

- 选取具有唯一标识性的标签,定位
- 尽量选取闭合的标签

## 步骤

### 提取数据

分析 html 结构

### 数据精炼

将已经获取到的数据,并将数据规范为想要的结构.

- `__refine()`
- `.strip()` ,去字符串前后空格.内置函数.

### 业务处理

业务重在排序上,`__sort()`,排序`storted()`

## 爬虫库

- Beautiful Soup
- Scrapy (多线程)

## 遇到的问题

- 爬虫,反爬虫,反反爬虫
- ip 有可能被封(寻找代理 ip 库)

## 建议

- 建议写平级函数,不建议多嵌套函数
- 块注释,python 中的模块,类注释的使用(写在类或方法的里面)

  ````py

      ```
        this is a module

      ```
        class Cpa():
          ```
          this is a class

          ```

  ````

- 单行代码注释

  - 在代码上面注释,之间留空行,有利于阅读,
  - 一个函数,尽量不要写多行代码(10-20 行之间)

    ```py

    # 通过 request.urlopen 方法,接受 url,url 就是要 抓取 网页的地址
    r = request.urlopen(Cpa.url)

    # 将 html 字节码转换为字符串
    html = str(html, encoding='utf-8')

    ```
